{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTDw40gwaknS"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6faj6wlagW4"
   },
   "source": [
    "- Author: Yunho Maeng (Yonsei University) yunhomaeng@yonsei.ac.kr\n",
    "- Paper link: TDB\n",
    "- This code guide you how to extract features from reviews using sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRbt152ta4P0"
   },
   "source": [
    "## Sentiment Score Extraction\n",
    "### NLTK \n",
    "- Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
    "https://www.nltk.org/api/nltk.sentiment.html\n",
    "- Reference code , Grishma Jena(2019) https://colab.research.google.com/drive/1Q4yorsQT6eVHmd8H07h7diinQEhCkyng#scrollTo=iFkqRxTo3iVc\n",
    "- Paper used the `compound score` to extract sentiment feature. Please see more discussion here. https://stackoverflow.com/questions/40325980/how-is-the-vader-compound-polarity-score-calculated-in-python-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "NKbJQL2FaXXF",
    "outputId": "20e9263e-e28d-4ec9-858b-1d1256e60b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/yunho/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "k1mP4Lm2llmr",
    "outputId": "1eb5efe5-c9b8-48d1-f806-929e0f7103b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great place to visit in Nashville. I like this movie but the theater is not comfortable\n",
      "-0.0652\n",
      "The food took too long to come, the service was slow.\n",
      "0.0\n",
      "Everything was amazing.\n",
      "0.5859\n",
      "Place closed down a month ago.\n",
      "0.0\n",
      "Had to wait in line for an hour, but the food was worth the wait.\n",
      "0.3291\n",
      "I like this movie but the theater is not comfortable\n",
      "-0.422\n",
      "The hero is not good man but story is so great\n",
      "0.8738\n"
     ]
    }
   ],
   "source": [
    "restaurant_reviews = [\"Great place to visit in Nashville. I like this movie but the theater is not comfortable\",\n",
    "\"The food took too long to come, the service was slow.\",\n",
    "\"Everything was amazing.\",\n",
    "\"Place closed down a month ago.\",\n",
    "\"Had to wait in line for an hour, but the food was worth the wait.\",\n",
    "\"I like this movie but the theater is not comfortable\",\n",
    "\"The hero is not good man but story is so great\",\n",
    "]\n",
    "  \n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in restaurant_reviews:\n",
    "     print(sentence)\n",
    "     # NLTK Sentiment Score\n",
    "     print(sentiment_analyzer.polarity_scores(sentence)['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5uFsw5gb7Wv"
   },
   "source": [
    "### Watson NLU version (if you needed) \n",
    "- This is initial version of mine. To use this approach more generally, I added the code as an open source version. \n",
    "- Github Link (Gist) https://gist.github.com/yunho0130/1d6edb1ac9b002480fa4a72de3f8de89 (This link is currently `private`. After publishing paper, it would be open to public) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ronEpM3ln1M2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOOqzf_Pcp_1"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun  6 15:58:06 2017\n",
    "@author: Yunho\n",
    "\"\"\"\n",
    "\n",
    "# Import Package\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle \n",
    "import json\n",
    "import csv\n",
    "sys.path.append(os.path.join(os.getcwd(),'..'))\n",
    "import watson_developer_cloud\n",
    "import watson_developer_cloud.natural_language_understanding.features.v1 as features\n",
    "print \"--sys.version--\"\n",
    "print sys.version\n",
    "\n",
    "# parameter management\n",
    "csv_file = \"VR_HMD_DATA_ALL_old.csv\"\n",
    "csv_output_file =\"test_data_w.csv\"\n",
    "\n",
    "wcs_username='your-own-watson-username'\n",
    "wcs_password='your-watson-password'\n",
    "pickle_csv_senti = 'temp_NLU_csv_dict.csv'\n",
    "\n",
    "\n",
    "# Watson API Credential\n",
    "input_test =  u\"Submerge yourself into the Galaxy VR world. Very fun and easy to work, love the controller, however not all games in oculus store are compatible. Also haven't figured out how to use as normal vr without oculus. but deffinetly worth every penny invested. Face your fears is a must download, feels so REAL!!!\"\n",
    "\n",
    "def watson_nlu_setiment(raw_text_input,nlu_name=wcs_username,nlu_pass=wcs_password):\n",
    "    try:\n",
    "        nlu = watson_developer_cloud.NaturalLanguageUnderstandingV1(version='2017-02-27',\n",
    "        username=nlu_name,password=nlu_pass)\n",
    "        raw_text = raw_text_input\n",
    "    # API implementation Sentiment\n",
    "        \n",
    "        print '=== NLU runing ==='\n",
    "        nlu.analyze(text=raw_text, features=[features.Sentiment()])\n",
    "        \n",
    "        sen_result = nlu.analyze(text=raw_text, features=[features.Sentiment()])\n",
    "        # string to json\n",
    "        json_sen_result = json.dumps(sen_result)\n",
    "        # json to dict\n",
    "        dict_sen_result = json.loads(json_sen_result)\n",
    "        # dict to score \n",
    "        sentiment_score = dict_sen_result['sentiment']['document']['score']\n",
    "    #    print sentiment_score\n",
    "    except: \n",
    "        sentiment_score = 'NULL'\n",
    "    return sentiment_score\n",
    "\n",
    "# CSV file load and make a sentiment score\n",
    "def csv_to_sent_score(pickle_file):\n",
    "    reader = []\n",
    "    temp_data = {}\n",
    "    fieldnames = ['no', 'senti_score', 'comments']\n",
    "    with open(pickle_csv_senti, 'w') as csvfile: \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        with open(csv_file, \"rU\") as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            print csvfile\n",
    "            i = 1\n",
    "            for row in reader:\n",
    "                temp_no = row['no']\n",
    "                writer.writerow({'no' : temp_no , 'senti_score' : watson_nlu_setiment(row['comments']), 'comments' : row['comments']})\n",
    "                print i\n",
    "                i = i+1\n",
    "    return 1\n",
    "\n",
    "## Main\n",
    "print '=== main==='\n",
    "csv_to_sent_score(pickle_csv_senti)\n",
    "print '=== main end ==='\n",
    "#print watson_nlu_setiment(input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c33IQf-gbPzE"
   },
   "source": [
    "## Sentence segmentation\n",
    "- Reference code, Grishma Jena(2019) https://colab.research.google.com/drive/1Q4yorsQT6eVHmd8H07h7diinQEhCkyng#scrollTo=iFkqRxTo3iVc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1bQzrl9gpcR"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAKYPuSBen0v"
   },
   "outputs": [],
   "source": [
    "sample_data = [\"Today is a cold Sunday morning. I am at the Nashville School of Law. \\\n",
    "               I am here for PyTennessee where I can learn more about Python.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0vVrvssbRyJ"
   },
   "outputs": [],
   "source": [
    "def get_sent_tokens(data):\n",
    "    \"\"\"Sentence tokenization\"\"\"\n",
    "    sentences = []\n",
    "    for sent in data:\n",
    "        sentences.extend(sent_tokenize(sent))\n",
    "    print(sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o6W1vkhLeVhF",
    "outputId": "8b2c4482-4ba3-43c0-8076-a34d03b91ea2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Today is a cold Sunday morning.', 'I am at the Nashville School of Law.', 'I am here for PyTennessee where I can learn more about Python.']\n"
     ]
    }
   ],
   "source": [
    "sample_sentences = get_sent_tokens(sample_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "U5uFsw5gb7Wv"
   ],
   "name": "Sentiment-Feature.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
